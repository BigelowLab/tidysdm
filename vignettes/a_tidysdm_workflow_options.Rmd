---
title: "tidysdm workflow functionalities"
output: rmarkdown::html_vignette
#output: rmarkdown::pdf_document
vignette: >
  %\VignetteIndexEntry{tidysdm overview}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
# set options to limit threads used by imported libraries
options(cores=2)
options(mc.cores=2)
# xgboost uses data.table
data.table::setDTthreads(2)
```

# SDMs with `tidymodels` : an overview of the workflow and functionality

[Intro/Abstract as in paper]

## Background

[intro to tidymodels]

## Workflow with `tidysdm`

### Assembling data - before modelling step

explaining all the pre processing of data;

#### Climate data

In `tidysdm`, environmental raster data are manipulated with [terra](https://cran.r-project.org/package=terra), and it is possible to use any `terra` [SpatRasterDataset](https://rdrr.io/cran/terra/man/sds.html), in which each climatic variable is a `terra` `SpatRaster` with a time dimension.

`tidysdm` is fully integrated with [pastclim](https://evolecolgroup.github.io/pastclim/dev/index.html). This offers several advantages:

-   easy download of environmental data
-   easy manipulation of present-day data, future predictions, and palaeoclimatic reconstructions
-   numerous available [datasets](https://evolecolgroup.github.io/pastclim/articles/a1_available_datasets.html)

#### Species data

Download presences

Presences are represented as spatial point objects using the library [sf](#0). All functions in `tidysdm` can work with `sf` objects, and the package extends several methods from the `tidymodels` universe to handle them.

-   introduce the problem that we work with only presences and (sometimes) biased presences)

##### Present-day data

Presences can be downloaded from online repositories (e.g GBIF) using packages such as [rgbif](https://cran.r-project.org/package=rgbif) . For an example on how to use `rgbif` see [Example 1](https://evolecolgroup.github.io/tidysdm/articles/a0_tidysdm_overview.html).

##### Time-scattered data

Palaeontological/archaeological data that need time series of palaeoclimatic reconstructions can be easily integrated as tidysdm does not limit the user to automatically associate points with a single raster. [Example 2](https://evolecolgroup.github.io/tidysdm/articles/a1_palaeodata_application.html) shows how to use time-scattered data based on [horses](https://evolecolgroup.github.io/tidysdm/dev/reference/horses.html) dataset.

Examples of how to use pastclim within tidysdm to perform SDM both on present-day and time-scattered data can be found in the respective vignettes: [Example 1](https://evolecolgroup.github.io/tidysdm/articles/a0_tidysdm_overview.html) and [Example 2](https://evolecolgroup.github.io/tidysdm/articles/a1_palaeodata_application.html).

#### Sample background or pseudo-absences

In most cases, true absences are rarely available. For this reason, there are various approaches implemented in `tidysdm` to sample pseudo-absences/background points.

**Sample background**

The `tidysdm` function `sample_background()` samples background points from a `raster` given a set of presences. The locations returned as the center points of the sampled cells, which can overlap with the presences (in contrast to pseudo-absences).

It provides commonly adopted techniques including:

-   random: background randomly sampled from the region covered by the `raster` (i.e. not NAs),

-   maximum distance ('dist_max'): background randomly sampled from the unioned buffers of maximum distance (in meters or map units) from presences. Areas that are in multiple buffers are not over-sampled (i.e. union of buffers or "thickening"),

-   'bias': background points are sampled according to a surface representing the biased sampling effort.

The `tidysdm` function `sample_background_time()` samples background points from a raster given a set of presences. The locations returned as the center points of the sampled cells,, which can overlap with the presences.

It provides commonly adopted techniques including:

-   random

-   maximum distance ('dist_max')

-   'bias': background points are sampled according to a surface representing the biased sampling effort. Note that the surface for each time step is normalised to sum to 1, it is possible to affect sampling effort within each time step (`n_per_time_step`).

**Sample pseudo-absences**

The `tidysdm` function `sample_pseudoabs()` samples pseudo-absence points from a `raster` given a set of presences. The locations returned as the center points of the sampled cells, which can not overlap with the presences.

It provides commonly adopted techniques including:

-   random: pseudo-absences randomly sampled from the region covered by the raster (i.e. not NAs)

-   minimum distance ('dist_min'): pseudo-absences randomly sampled from the region excluding a buffer of minimum distance (in meters or map units) from presences,

-   maximum distance ('dist_max'): pseudo-absences randomly sampled from the unioned buffers of maximum distance (in meters or map units) from presences. Areas that are in multiple buffers are not over-sampled (i.e. union of buffers or "thickening"),

-   a disc identified by minimum and maximum distance ('dist_disc'): pseudo-absences randomly sampled from the unioned discs around presences with the two values defining the minimum and maximum distance from presences.

The `tidysdm` function `sample_pseudoabs_time()` samples pseudo-absence points from a raster given a set of presences. The locations returned as the center points of the sampled cells, which can not overlap with the presences.

It provides commonly adopted techniques including:

-   random

-   minimum distance ('dist_min')

-   maximum distance ('dist_max')

-   a disc identified by minimum and maximum distance ('dist_disc')

#### Thinning

Once we have a set of presences for a species we need to consider the collection/distribution of this data. Generally, presences are the collation of haphazard efforts, leading to spatial sampling biases. A common solution is to thin the data.

**Cell-level thinning**

The `tidysdm` function `thin_by_cell()` thins a dataset so that only one observation per `raster` cell is retained.

The `tidysdm` function `thin_by_cell_time()` thins a dataset so that only one observation per `raster` cell per time slice is retained. We use a raster with layers as time slices to define the data cube on which thinning is enforced (see details below on how time should be formatted).

**Distance-based thinning**

The `tidysdm` function `thin_by_dist()` thins a dataset so that only observations that have a distance from each other greater than a minimum distance are retained (removing close-by points).

The `tidysdm` function `thin_by_dist_time()` thins a dataset so that only observations that have a distance from each other greater than a minimum distance in space and minimum interval in time are retained.

Further thinning can be achieved by aggregating cells in the raster before thinning, as achieved by setting `agg_fact` \> 1 (aggregation works in a manner equivalent to [`terra::aggregate()`](http://127.0.0.1:43143/help/library/terra/help/aggregate)).

#### Choice of variables

\- violinplot

Remove collinear variables

\- correlation

\- VIF

\- correlation and VIF

### Pre-processing of models / Modelling

[rationale for tidymodels: why are we using tidymodels, flexibility of having each step of the analysis under control (and with the option to parallelise for improving computing time) and easily add/chose various methods. ]

#### Creating workflow

`tidymodels` allows to fit different models by changing the model specification with the same code defining the rest of the workflow. This step is standardised by using `workflowsets`:[explain]. Multiple algorithms can be easily investigated : [list/explain].

`tidysdm` provides functions to simplify these steps (e.g., automatically generating model specifications with tuning for hyperparameters usually studied in SDMs) and expands methods from `tidymodels` that are not natively compatible with sf objects.

\

\- recipe

\- model specifications

#### Create data folds

#### Tune the model

\- algorithms available

\- how to add additional algorithms (parsnip)

### **Evaluation**

Metrics available

### **Ensemble**

Simple ensemble

Stacked ensemble

Repeated ensemble

Ensemble from individual workflows

Averaging ensembles

Evaluation of ensembles

### **Projection**

Predict

Predict_raster 

\- same time slice

\- different time slice

Convert into binary

Compare niche

Managing extrapolation:

\- MESS

\- area of applicability (<https://rdrr.io/cran/waywiser/man/ww_area_of_applicability.html>)

\- clamping
